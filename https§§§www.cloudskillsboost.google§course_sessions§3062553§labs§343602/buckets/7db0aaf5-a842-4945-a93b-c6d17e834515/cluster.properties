#Cluster properties
#Wed Jun 28 09:01:56 PDT 2023
hdfs\:dfs.namenode.secondary.http-address=0.0.0.0\:9868
dataproc\:dataproc.await-new-workers-service-registration=false
dataproc\:internal.node.main.memory-protection.enabled=true
yarn\:yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs=86400
mapred\:mapreduce.job.reduce.slowstart.completedmaps=0.95
mapred\:mapreduce.reduce.memory.mb=3072
dataproc\:dataproc.control.task.request.interval.millis=5000
hdfs\:dfs.datanode.https.address=0.0.0.0\:9865
dataproc\:dataproc.conscrypt.provider.enable=true
dataproc\:dataproc.cluster-ttl.report-yarn-activity=true
spark\:spark.dataproc.sql.optimizer.leftsemijoin.conversion.enabled=true
core\:fs.gs.block.size=134217728
mapred\:mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService
mapred\:yarn.app.mapreduce.am.resource.cpu-vcores=1
dataproc\:dataproc.worker.custom.init.actions.mode=RUN_BEFORE_SERVICES
mapred\:yarn.app.mapreduce.am.command-opts=-Xmx2457m
spark\:spark.dataproc.sql.parquet.enableFooterCache=true
spark\:spark.ui.port=0
distcp\:mapreduce.map.java.opts=-Xmx576m
dataproc\:dataproc.control.task.stream.duration.sec=600
yarn\:yarn.scheduler.maximum-allocation-mb=6144
hdfs\:dfs.datanode.address=0.0.0.0\:9866
dataproc\:dataproc.heartbeat.master.frequency.sec=30
hdfs\:dfs.namenode.service.handler.count=30
hdfs\:dfs.datanode.http.address=0.0.0.0\:9864
dataproc\:simplified.scaling.enable=true
mapred\:mapreduce.map.memory.mb=3072
hadoop-env\:HADOOP_DATANODE_OPTS=-Xmx512m
core\:fs.gs.metadata.cache.enable=false
yarn\:yarn.scheduler.minimum-allocation-mb=1
yarn\:yarn.nodemanager.resource.cpu-vcores=2
dataproc\:dataproc.master.custom.init.actions.mode=RUN_BEFORE_SERVICES
yarn-env\:YARN_NODEMANAGER_HEAPSIZE=768
spark\:spark.dataproc.sql.joinConditionReorder.enabled=true
mapred-env\:HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1920
capacity-scheduler\:yarn.scheduler.capacity.root.default.ordering-policy=fair
dataproc\:dataproc.scheduler.max-memory-used=0.9
spark\:spark.scheduler.mode=FAIR
dataproc\:internal.feature_flag_autoscaler_drc=true
spark\:spark.driver.memory=1920m
spark\:spark.executor.instances=2
spark-env\:SPARK_DAEMON_MEMORY=1920m
dataproc\:yarn.log-aggregation.enabled=true
spark\:spark.yarn.am.memory=640m
distcp\:mapreduce.reduce.java.opts=-Xmx576m
yarn\:yarn.nodemanager.address=0.0.0.0\:8026
hdfs\:dfs.namenode.secondary.https-address=0.0.0.0\:9869
hdfs\:dfs.namenode.https-address=0.0.0.0\:9871
spark\:spark.dataproc.sql.local.rank.pushdown.enabled=true
spark\:spark.sql.cbo.enabled=true
mapred\:mapreduce.map.cpu.vcores=1
spark\:spark.executor.memory=2688m
dataproc\:dataproc.scheduler.max-concurrent-jobs=5
dataproc\:dataproc.performance.metrics.listener.enabled=true
hdfs\:dfs.namenode.servicerpc-address=mjtelco-m\:8051
dataproc\:dataproc.monitoring.stackdriver.enable=false
yarn\:yarn.resourcemanager.decommissioning-nodes-watcher.decommission-if-no-shuffle-data=true
spark\:spark.driver.maxResultSize=960m
dataproc\:dataproc.cluster-metrics.collect-yarn-node-metrics.enabled=true
mapred\:mapreduce.map.java.opts=-Xmx2457m
dataproc\:dataproc.control.task.invalidation.interval.millis=5000
spark\:spark.executor.cores=1
distcp\:mapreduce.map.memory.mb=768
yarn-env\:YARN_TIMELINESERVER_HEAPSIZE=1920
dataproc\:agent.spark.driver.empty.jar=true
core\:hadoop.ssl.enabled.protocols=TLSv1,TLSv1.1,TLSv1.2
yarn-env\:YARN_RESOURCEMANAGER_HEAPSIZE=1920
dataproc\:am.primary_only=false
mapred\:mapreduce.task.io.sort.mb=256
dataproc\:job.history.to-gcs.enabled=true
mapred\:mapreduce.job.maps=27
mapred\:mapreduce.job.reduces=9
dataproc\:agent.ha.enabled=false
dataproc\:dataproc.heartbeat.worker.frequency.sec=-1
hdfs\:dfs.datanode.ipc.address=0.0.0.0\:9867
mapred\:yarn.app.mapreduce.am.resource.mb=3072
distcp\:mapreduce.reduce.memory.mb=768
hive\:hive.fetch.task.conversion=none
yarn\:yarn.nodemanager.resource.memory-mb=6144
hdfs\:dfs.namenode.lifeline.rpc-address=mjtelco-m\:8050
spark\:spark.extraListeners=com.google.cloud.spark.performance.DataprocMetricsListener
mapred\:mapreduce.reduce.java.opts=-Xmx2457m
dataproc\:dataproc.components-to-monitor-service-registration=hdfs yarn
hdfs\:dfs.namenode.http-address=0.0.0.0\:9870
dataproc\:dataproc.job.metrics.monitor.interval.sec=60
dataproc\:dataproc.monitoring.default.metrics.system.enable=true
dataproc\:dataproc.monitoring.default.metrics.enable=true
spark\:spark.executorEnv.OPENBLAS_NUM_THREADS=1
dataproc\:dataproc.cluster-health.collect-component-node-names=true
mapred\:mapreduce.reduce.cpu.vcores=1
hdfs\:dfs.namenode.handler.count=60
